{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab6.2: Topic modeling using gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how LDA models can be built and applied using the *gensim* package.\n",
    "\n",
    "Credits:\n",
    "\n",
    "This notebook is an adaptation of a blog from Susan Li's:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from:\n",
    "\n",
    "https://www.kaggle.com/therohk/million-headlines/data\n",
    "\n",
    "You can also find this file in the lab6 folder.\n",
    "\n",
    "We read the CSV file using the pandas framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### Adapt the path below to point to your local copy of the data set\n",
    "data = pd.read_csv('abcnews-date-text.csv', on_bad_lines=\"warn\");\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244184\n",
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the *gensim* package to build our LDA models from the data.\n",
    "Before building the model, we are going to preprocess the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "We will perform the following steps:\n",
    "\n",
    "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* All stopwords are removed.\n",
    "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "* Words are stemmed — words are reduced to their root form.\n",
    "\n",
    "In order to apply these processing steps, we first load the gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/timofeypolivanov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "           # result.append(token)\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the preprocessing to all the headlines and print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [decides, community, broadcasting, licence]\n",
       "1                         [witness, aware, defamation]\n",
       "2           [call, infrastructure, protection, summit]\n",
       "3                          [staff, aust, strike, rise]\n",
       "4              [strike, affect, australian, traveller]\n",
       "5               [ambitious, olsson, win, triple, jump]\n",
       "6          [antic, delighted, record, breaking, barca]\n",
       "7    [aussie, qualifier, stosur, waste, memphis, ma...\n",
       "8             [aust, address, security, council, iraq]\n",
       "9                       [australia, locked, timetable]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "### print the first 10 results\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "We are going to use the *Dictionary* function to derive a dictionary with counts from the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcasting\n",
      "1 community\n",
      "2 decides\n",
      "3 licence\n",
      "4 aware\n",
      "5 defamation\n",
      "6 witness\n",
      "7 call\n",
      "8 infrastructure\n",
      "9 protection\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim filter_extremes\n",
    "Filter out tokens that appear in\n",
    "less than 15 documents (absolute number) or\n",
    "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow\n",
    "For each document we create a dictionary reporting how many words and how many times those words appear. \n",
    "Gensim provides the *doc2bow* function to create a BoW vector representation for a document.\n",
    "Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(164, 1), (241, 1), (615, 1), (891, 1), (4175, 1), (4176, 1), (4177, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Bag Of Words for our sample preprocessed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 164 (\"govt\") appears 1 time.\n",
      "Word 241 (\"group\") appears 1 time.\n",
      "Word 615 (\"local\") appears 1 time.\n",
      "Word 891 (\"want\") appears 1 time.\n",
      "Word 4175 (\"compulsory\") appears 1 time.\n",
      "Word 4176 (\"ratepayer\") appears 1 time.\n",
      "Word 4177 (\"voting\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6161125947380649),\n",
      " (1, 0.3308772069039591),\n",
      " (2, 0.5681053683635203),\n",
      " (3, 0.43379930266554434)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’. This takes a while.\n",
    "Look at the documentation of *gensim* for further details:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "\n",
    "As parameters, we pass the corpus data as BoW (a list of lists of tuples), the prefixed number of topics, the actual words and the number of passes and workers used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we will explore the words occuring in that topic and its relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.034*\"case\" + 0.024*\"court\" + 0.024*\"police\" + 0.021*\"woman\" + 0.020*\"child\" + 0.019*\"vaccine\" + 0.017*\"murder\" + 0.015*\"death\" + 0.014*\"charged\" + 0.014*\"face\"\n",
      "Topic: 1 \n",
      "Words: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\" + 0.011*\"drum\" + 0.010*\"search\" + 0.010*\"farmer\" + 0.010*\"help\" + 0.010*\"announces\"\n",
      "Topic: 2 \n",
      "Words: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\" + 0.012*\"bushfire\" + 0.012*\"hotel\" + 0.012*\"pandemic\" + 0.011*\"road\" + 0.010*\"say\"\n",
      "Topic: 3 \n",
      "Words: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"plan\" + 0.015*\"live\" + 0.015*\"federal\" + 0.012*\"gold\" + 0.012*\"care\" + 0.010*\"aged\" + 0.010*\"rural\"\n",
      "Topic: 4 \n",
      "Words: 0.043*\"covid\" + 0.038*\"coronavirus\" + 0.019*\"open\" + 0.017*\"lockdown\" + 0.016*\"melbourne\" + 0.015*\"dy\" + 0.014*\"final\" + 0.014*\"sydney\" + 0.012*\"hospital\" + 0.012*\"crash\"\n",
      "Topic: 5 \n",
      "Words: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"say\" + 0.018*\"people\" + 0.017*\"minister\" + 0.015*\"change\" + 0.014*\"morrison\" + 0.012*\"labor\" + 0.012*\"andrew\" + 0.011*\"country\"\n",
      "Topic: 6 \n",
      "Words: 0.038*\"trump\" + 0.036*\"queensland\" + 0.031*\"victoria\" + 0.021*\"record\" + 0.020*\"news\" + 0.017*\"covid\" + 0.016*\"market\" + 0.014*\"south\" + 0.014*\"coronavirus\" + 0.012*\"brisbane\"\n",
      "Topic: 7 \n",
      "Words: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\" + 0.012*\"commission\" + 0.012*\"power\" + 0.012*\"fight\" + 0.010*\"town\" + 0.009*\"perth\"\n",
      "Topic: 8 \n",
      "Words: 0.078*\"australia\" + 0.023*\"donald\" + 0.017*\"restriction\" + 0.015*\"coronavirus\" + 0.012*\"world\" + 0.011*\"australian\" + 0.010*\"climate\" + 0.010*\"win\" + 0.010*\"attack\" + 0.009*\"high\"\n",
      "Topic: 9 \n",
      "Words: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\" + 0.011*\"say\" + 0.011*\"amid\" + 0.011*\"president\" + 0.010*\"biden\" + 0.009*\"student\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.018*\"coronavirus\" + 0.015*\"covid\" + 0.012*\"market\" + 0.010*\"live\" + 0.008*\"record\" + 0.008*\"price\" + 0.008*\"queensland\" + 0.008*\"victoria\" + 0.008*\"australia\" + 0.007*\"case\"\n",
      "Topic: 1 Word: 0.016*\"police\" + 0.013*\"murder\" + 0.010*\"charged\" + 0.010*\"woman\" + 0.009*\"court\" + 0.009*\"child\" + 0.008*\"death\" + 0.008*\"missing\" + 0.007*\"story\" + 0.007*\"interview\"\n",
      "Topic: 2 Word: 0.012*\"lockdown\" + 0.009*\"care\" + 0.009*\"aged\" + 0.007*\"australian\" + 0.007*\"history\" + 0.007*\"open\" + 0.006*\"september\" + 0.006*\"coronavirus\" + 0.006*\"smith\" + 0.005*\"australia\"\n",
      "Topic: 3 Word: 0.017*\"country\" + 0.012*\"hour\" + 0.009*\"friday\" + 0.008*\"wednesday\" + 0.007*\"quarantine\" + 0.006*\"pandemic\" + 0.006*\"coronavirus\" + 0.006*\"inquest\" + 0.006*\"july\" + 0.006*\"grand\"\n",
      "Topic: 4 Word: 0.015*\"drum\" + 0.012*\"morrison\" + 0.011*\"scott\" + 0.010*\"shooting\" + 0.010*\"monday\" + 0.010*\"tuesday\" + 0.007*\"weather\" + 0.006*\"murray\" + 0.006*\"speaks\" + 0.006*\"peter\"\n",
      "Topic: 5 Word: 0.010*\"health\" + 0.008*\"andrew\" + 0.007*\"government\" + 0.006*\"thursday\" + 0.006*\"liberal\" + 0.006*\"funding\" + 0.006*\"mental\" + 0.006*\"say\" + 0.005*\"christmas\" + 0.005*\"school\"\n",
      "Topic: 6 Word: 0.018*\"crash\" + 0.008*\"sport\" + 0.008*\"finance\" + 0.008*\"coronavirus\" + 0.007*\"killed\" + 0.007*\"fatal\" + 0.007*\"road\" + 0.006*\"grandstand\" + 0.006*\"briefing\" + 0.006*\"dy\"\n",
      "Topic: 7 Word: 0.026*\"trump\" + 0.016*\"election\" + 0.008*\"labor\" + 0.008*\"government\" + 0.006*\"say\" + 0.006*\"federal\" + 0.006*\"state\" + 0.005*\"biden\" + 0.005*\"leader\" + 0.005*\"parliament\"\n",
      "Topic: 8 Word: 0.016*\"donald\" + 0.010*\"australia\" + 0.009*\"vaccine\" + 0.009*\"world\" + 0.009*\"climate\" + 0.007*\"michael\" + 0.007*\"coronavirus\" + 0.006*\"turnbull\" + 0.006*\"league\" + 0.006*\"covid\"\n",
      "Topic: 9 Word: 0.021*\"news\" + 0.013*\"rural\" + 0.008*\"hill\" + 0.008*\"national\" + 0.007*\"violence\" + 0.007*\"korea\" + 0.007*\"investigation\" + 0.006*\"domestic\" + 0.006*\"north\" + 0.006*\"october\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, can you distinguish different topics using the words in each topic and their corresponding weights? Do you observe any differences with the BoW version? Do these differences make sense given the information value weighing by the *tfidf* method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "We will check where our test document would be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 4310 is already represented in the correct way. We can directly pass it to our *lda_model* to get the similarity scores for each topic. We represent each topic by printing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.40960708260536194\t \n",
      "Topic: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"plan\" + 0.015*\"live\" + 0.015*\"federal\" + 0.012*\"gold\" + 0.012*\"care\" + 0.010*\"aged\" + 0.010*\"rural\"\n",
      "\n",
      "Score: 0.26242026686668396\t \n",
      "Topic: 0.038*\"trump\" + 0.036*\"queensland\" + 0.031*\"victoria\" + 0.021*\"record\" + 0.020*\"news\" + 0.017*\"covid\" + 0.016*\"market\" + 0.014*\"south\" + 0.014*\"coronavirus\" + 0.012*\"brisbane\"\n",
      "\n",
      "Score: 0.2404140830039978\t \n",
      "Topic: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"say\" + 0.018*\"people\" + 0.017*\"minister\" + 0.015*\"change\" + 0.014*\"morrison\" + 0.012*\"labor\" + 0.012*\"andrew\" + 0.011*\"country\"\n",
      "\n",
      "Score: 0.012508699670433998\t \n",
      "Topic: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\" + 0.011*\"say\" + 0.011*\"amid\" + 0.011*\"president\" + 0.010*\"biden\" + 0.009*\"student\"\n",
      "\n",
      "Score: 0.012508688494563103\t \n",
      "Topic: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\" + 0.012*\"commission\" + 0.012*\"power\" + 0.012*\"fight\" + 0.010*\"town\" + 0.009*\"perth\"\n",
      "\n",
      "Score: 0.012508652172982693\t \n",
      "Topic: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\" + 0.012*\"bushfire\" + 0.012*\"hotel\" + 0.012*\"pandemic\" + 0.011*\"road\" + 0.010*\"say\"\n",
      "\n",
      "Score: 0.012508128769695759\t \n",
      "Topic: 0.034*\"case\" + 0.024*\"court\" + 0.024*\"police\" + 0.021*\"woman\" + 0.020*\"child\" + 0.019*\"vaccine\" + 0.017*\"murder\" + 0.015*\"death\" + 0.014*\"charged\" + 0.014*\"face\"\n",
      "\n",
      "Score: 0.012508128769695759\t \n",
      "Topic: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\" + 0.011*\"drum\" + 0.010*\"search\" + 0.010*\"farmer\" + 0.010*\"help\" + 0.010*\"announces\"\n",
      "\n",
      "Score: 0.012508128769695759\t \n",
      "Topic: 0.043*\"covid\" + 0.038*\"coronavirus\" + 0.019*\"open\" + 0.017*\"lockdown\" + 0.016*\"melbourne\" + 0.015*\"dy\" + 0.014*\"final\" + 0.014*\"sydney\" + 0.012*\"hospital\" + 0.012*\"crash\"\n",
      "\n",
      "Score: 0.012508128769695759\t \n",
      "Topic: 0.078*\"australia\" + 0.023*\"donald\" + 0.017*\"restriction\" + 0.015*\"coronavirus\" + 0.012*\"world\" + 0.011*\"australian\" + 0.010*\"climate\" + 0.010*\"win\" + 0.010*\"attack\" + 0.009*\"high\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic that our model assigned, which is the accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing our LDA model\n",
    "\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. \n",
    "To do so, we’ll use a popular visualization package, *pyLDAvis* which is designed to help interactively with:\n",
    "\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "\n",
    "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
    "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n",
    "\n",
    "You need to install *pyldavis* through the command line, following the instructions:\n",
    "\n",
    "https://anaconda.org/conda-forge/pyldavis\n",
    "\n",
    "WARNING: running the next cell takes a long time and you need some memory to run it. However, the result is spectacular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el93943136815929128609631440\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el93943136815929128609631440_data = {\"mdsDat\": {\"x\": [-0.27631935342644476, -0.28260507811030056, 0.15343438226364778, 0.07886004689012117, 0.15300488569004655, -0.05443736335190771, 0.21471583580482675, 0.013661795813160536, 0.09733104071253708, -0.09764619228568706], \"y\": [0.024203927580949566, -0.03628295170578588, 0.23723368959690547, -0.26210435831307827, -0.14135384353606126, -0.10873526094010535, -0.09548665747358882, 0.04175402070762615, 0.25448965056243533, 0.08628178352070305], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.998771234014702, 10.899436515429473, 10.895446894395342, 10.03993406688632, 9.78956004370327, 9.724576886186792, 9.680823742112011, 9.099868696144082, 8.978678942987052, 8.892902978140956]}, \"tinfo\": {\"Term\": [\"australia\", \"police\", \"trump\", \"covid\", \"queensland\", \"case\", \"victoria\", \"coronavirus\", \"election\", \"home\", \"court\", \"government\", \"health\", \"donald\", \"school\", \"coast\", \"record\", \"child\", \"news\", \"vaccine\", \"woman\", \"tasmania\", \"national\", \"border\", \"open\", \"people\", \"murder\", \"minister\", \"victorian\", \"plan\", \"coast\", \"national\", \"live\", \"federal\", \"plan\", \"gold\", \"care\", \"aged\", \"rural\", \"industry\", \"local\", \"fear\", \"park\", \"farm\", \"week\", \"port\", \"green\", \"social\", \"tourism\", \"land\", \"housing\", \"extended\", \"prince\", \"closure\", \"tree\", \"territory\", \"impact\", \"data\", \"mask\", \"project\", \"government\", \"concern\", \"council\", \"regional\", \"future\", \"funding\", \"beach\", \"water\", \"health\", \"people\", \"minister\", \"morrison\", \"labor\", \"andrew\", \"country\", \"service\", \"show\", \"rate\", \"rule\", \"assault\", \"parliament\", \"medium\", \"aboriginal\", \"push\", \"election\", \"sport\", \"law\", \"briefing\", \"told\", \"hour\", \"parent\", \"remote\", \"decision\", \"defends\", \"increase\", \"legal\", \"morning\", \"opposition\", \"budget\", \"action\", \"refugee\", \"change\", \"indigenous\", \"say\", \"need\", \"government\", \"call\", \"community\", \"campaign\", \"case\", \"child\", \"vaccine\", \"murder\", \"charged\", \"trial\", \"scott\", \"charge\", \"court\", \"quarantine\", \"accused\", \"drug\", \"alleged\", \"abuse\", \"face\", \"arrested\", \"zealand\", \"look\", \"investigation\", \"jailed\", \"protester\", \"appeal\", \"shot\", \"coal\", \"kid\", \"prime\", \"rape\", \"allegation\", \"hears\", \"march\", \"woman\", \"sexual\", \"test\", \"police\", \"death\", \"life\", \"year\", \"shooting\", \"trump\", \"queensland\", \"victoria\", \"record\", \"news\", \"market\", \"price\", \"street\", \"interview\", \"india\", \"warning\", \"travel\", \"video\", \"wall\", \"christmas\", \"fall\", \"michael\", \"mental\", \"close\", \"east\", \"share\", \"free\", \"company\", \"alan\", \"cyclone\", \"sale\", \"tuesday\", \"george\", \"thursday\", \"outback\", \"trade\", \"bank\", \"brisbane\", \"south\", \"covid\", \"coronavirus\", \"australian\", \"year\", \"australia\", \"donald\", \"restriction\", \"climate\", \"win\", \"violence\", \"baby\", \"near\", \"cricket\", \"hit\", \"take\", \"hong\", \"kill\", \"footage\", \"johnson\", \"kong\", \"domestic\", \"airport\", \"leaf\", \"best\", \"survivor\", \"whale\", \"politics\", \"response\", \"aussie\", \"music\", \"artist\", \"breach\", \"boris\", \"early\", \"shark\", \"security\", \"high\", \"world\", \"centre\", \"attack\", \"chinese\", \"killed\", \"island\", \"coronavirus\", \"million\", \"australian\", \"china\", \"canberra\", \"covid\", \"border\", \"north\", \"protest\", \"amid\", \"president\", \"biden\", \"liberal\", \"program\", \"john\", \"story\", \"talk\", \"hobart\", \"david\", \"crisis\", \"international\", \"peter\", \"jail\", \"sentenced\", \"korea\", \"chief\", \"meet\", \"monday\", \"warns\", \"thousand\", \"wednesday\", \"rollout\", \"killing\", \"staff\", \"strike\", \"military\", \"west\", \"student\", \"china\", \"worker\", \"game\", \"say\", \"south\", \"australian\", \"lockdown\", \"dy\", \"final\", \"tasmanian\", \"update\", \"weather\", \"mark\", \"doctor\", \"friday\", \"lead\", \"outbreak\", \"race\", \"grand\", \"patient\", \"truck\", \"smith\", \"cut\", \"indonesia\", \"online\", \"injured\", \"mount\", \"global\", \"tourist\", \"wild\", \"latest\", \"open\", \"king\", \"tiger\", \"medical\", \"beat\", \"point\", \"super\", \"hospital\", \"covid\", \"coronavirus\", \"melbourne\", \"crash\", \"sydney\", \"australian\", \"storm\", \"home\", \"tasmania\", \"business\", \"royal\", \"return\", \"commission\", \"power\", \"fight\", \"town\", \"rain\", \"station\", \"number\", \"testing\", \"prison\", \"hill\", \"arrest\", \"release\", \"festival\", \"rugby\", \"james\", \"building\", \"save\", \"womens\", \"ship\", \"know\", \"film\", \"animal\", \"good\", \"track\", \"making\", \"star\", \"perth\", \"resident\", \"adelaide\", \"world\", \"sydney\", \"school\", \"missing\", \"guilty\", \"drum\", \"search\", \"announces\", \"northern\", \"emergency\", \"finance\", \"daniel\", \"white\", \"fatal\", \"teen\", \"rescue\", \"facebook\", \"bushfires\", \"cancer\", \"great\", \"continues\", \"money\", \"like\", \"france\", \"human\", \"united\", \"pleads\", \"drone\", \"boat\", \"flooding\", \"treatment\", \"southern\", \"police\", \"family\", \"dead\", \"farmer\", \"help\", \"house\", \"crash\", \"woman\", \"victorian\", \"premier\", \"claim\", \"speaks\", \"hotel\", \"pandemic\", \"road\", \"black\", \"body\", \"question\", \"find\", \"history\", \"club\", \"expert\", \"turnbull\", \"result\", \"released\", \"economy\", \"loss\", \"kohler\", \"paul\", \"recovery\", \"coach\", \"day\", \"inside\", \"berejiklian\", \"football\", \"female\", \"cabinet\", \"hunt\", \"time\", \"bushfire\", \"player\", \"long\", \"say\", \"team\", \"state\", \"report\", \"death\"], \"Freq\": [42910.0, 32982.0, 21370.0, 39713.0, 20511.0, 21118.0, 17516.0, 41816.0, 17590.0, 14530.0, 15010.0, 21786.0, 13963.0, 12832.0, 12019.0, 13529.0, 11658.0, 11961.0, 11384.0, 11698.0, 18508.0, 10677.0, 11653.0, 10576.0, 10539.0, 10876.0, 10665.0, 10418.0, 9418.0, 10531.0, 13528.322498627402, 11652.369868690781, 10442.264215374573, 10142.485341804688, 10530.84243287976, 8406.50290460999, 8044.246341099524, 6868.6589152392935, 6572.354621751531, 6565.278473134855, 6174.00064765386, 6121.438115494215, 5842.184850696051, 5448.82303155263, 5323.785297774098, 5102.457941283693, 5074.86781402584, 4482.649307915333, 4222.249742041161, 4155.722880703989, 4115.493001839268, 3823.810270767595, 3592.1393276332237, 3412.6725829065867, 3330.980974322988, 3288.6036075696234, 3130.1402499505884, 3102.6767968173135, 3076.0001062989795, 3594.323277552763, 15300.339480838793, 5696.060747256844, 5886.25675890253, 5546.233861714559, 3872.471994277055, 3893.7101842905145, 3992.784437448155, 4318.659752320561, 13962.67485129111, 10876.08984015009, 10417.520077821955, 8768.66409548638, 7609.996208568089, 7124.0916183614245, 6811.857152758733, 6151.250536346231, 5528.649535489325, 5469.060787093378, 5372.689058077969, 5126.0057562697175, 5071.638761192786, 4985.7019729471, 4519.349548205558, 3960.3072901752416, 17586.09767664101, 3689.5282008237023, 3921.6212591472467, 3523.0060077917014, 3515.4794648406287, 3353.3961047645225, 3285.0924419545904, 2949.0582823230366, 2888.9792807310732, 2861.0788200154398, 2808.3790284396955, 2730.2089129865794, 2642.05299379189, 2508.0819569075065, 5962.073905877809, 4022.566019722003, 3294.877804377816, 9347.33589732551, 6649.331793878064, 11196.600647709529, 3908.519192516143, 6485.363942774755, 4838.652282804981, 4361.0217503235135, 3583.4242177685614, 21117.662957463795, 11960.937883746883, 11697.920414370541, 10664.534419969796, 8586.891756375719, 8193.00261963613, 7955.395345451844, 6447.204101313324, 15008.622298273809, 5938.626291470582, 5903.8958469828, 5549.633325381416, 5425.844179792658, 4887.7557674147365, 8356.440072619676, 4407.111875562875, 4005.5202751895977, 3967.3827192960734, 3777.106807279111, 3756.5034448912857, 3619.314764071402, 3564.3354543362766, 3442.63504471696, 3143.4263286265996, 3129.962858323438, 3024.6035680977316, 2959.117214292223, 2896.695462577981, 2660.811866518791, 2608.027470640594, 12926.751357192537, 3807.025852171803, 6369.417381751726, 14488.830162626293, 8910.023035535598, 5158.29759558124, 6870.114052268393, 3693.9344141718198, 21369.517722587592, 20510.585114011494, 17515.20971562723, 11657.747514548913, 11383.906960541632, 9186.202167673828, 5555.3703857297905, 5505.973417969338, 5250.738918385148, 4454.4875301606335, 4306.631179213476, 4160.868147470658, 4156.898757668938, 4147.67516033548, 4144.960604799861, 4112.254694964599, 3885.305122365346, 3868.8902279235763, 3618.0559331752465, 3387.676147099049, 3340.089759738479, 3280.9052951127046, 3183.3146433409943, 3122.7398928358202, 2972.572448051682, 2893.9105674594066, 2876.96806925788, 2850.854313278325, 2767.6670337377063, 2766.0111048885387, 3724.054053433692, 3756.2541895750287, 6950.263198058335, 8172.016761026005, 9806.560036062807, 8076.411067167996, 6394.819003018353, 3463.437522076868, 42909.50548963776, 12831.691210176017, 9253.345147376584, 5669.773580406944, 5651.775647413963, 4433.0893914708595, 4367.805467070388, 4171.1435560758, 3876.8011848395013, 3731.6757317873958, 3527.73489044029, 3322.5740980067267, 3280.118928254818, 3153.970292639042, 3147.9449088306906, 3119.752421372949, 3100.322706392225, 2876.070205186042, 2668.771613245076, 2472.876242884801, 2371.789818720607, 2333.116830726756, 2314.625736930904, 2237.4246573829428, 2238.328144386851, 2214.9459622746394, 2158.0378214528337, 2101.2271331037737, 2082.729115053279, 2079.3618756660203, 3517.15898906244, 3186.290148771464, 4761.5898802202255, 6870.85427778681, 3588.9173480075224, 5300.586684286013, 3446.160246497027, 3807.308082978018, 4048.391395589107, 8231.90628662617, 3708.5405147574334, 6123.178390567442, 3927.318238626282, 3507.0139301956783, 3288.5257427524366, 10575.35876017575, 9155.18927343192, 7523.932666192808, 6140.2008007604445, 5821.877550830253, 5202.032933597371, 4965.367740152285, 4898.702320905159, 4841.036763826577, 4385.22360186942, 4221.115721133704, 4111.528489797936, 4053.7946593084307, 4019.9027700692664, 3906.112902688591, 3905.843375566356, 3773.225841365352, 3730.669342975469, 3712.809731981694, 3580.3203378019416, 3575.5483320801004, 3533.524009643288, 3463.980152821365, 3290.9182651930973, 3193.568788014164, 3007.1627603199254, 2915.1556775459, 2865.689808069759, 2734.6828130623, 2475.660370302965, 6958.344521019839, 5073.028285641678, 7719.957857033053, 4416.671150146538, 3631.54271910021, 6164.426143068407, 4626.383121865047, 3893.099939615915, 9126.190267938628, 7950.573265466303, 7797.146088447387, 6191.187694929455, 4864.296117620315, 4481.157782530199, 4459.642412133741, 4239.582205528124, 3685.6749062119425, 3626.822742264857, 3563.4703514420185, 3207.7391461610114, 3164.5105931977323, 3091.610975496077, 3030.4185414103918, 2954.3511393241192, 2948.5694446319003, 2924.6427945997893, 2908.440709820345, 2812.964636951978, 2630.283575989874, 2612.966134895999, 2357.863755915963, 2294.32268271524, 3560.962194563957, 10535.113030665132, 2149.3207825216987, 2154.4626309243977, 2025.1615645427091, 4650.891783336713, 2517.9201766954975, 3059.397770763192, 6715.125182408943, 23683.925369283337, 20948.262178034278, 8826.891324387268, 6557.820379640224, 7540.017656353212, 6013.156741602956, 3362.666145199831, 14529.566195849251, 10676.873323139753, 9169.784905430724, 7560.3324746085445, 7137.270288043429, 6235.86223438613, 6195.44050678341, 6127.313051399772, 4906.601860677544, 4516.4469900623635, 4326.593312845868, 4174.808490856832, 4083.464120947209, 4026.4392671851956, 3924.575865215716, 3856.3821384521066, 3323.004326722245, 3235.9304082544095, 3232.738416247849, 3211.8188300988036, 3180.161373304238, 3079.522561546685, 3063.1716480493, 2925.3727094831834, 2740.196647438662, 2584.259613592249, 2557.681929588408, 2543.0864925015017, 2453.4918777321445, 2439.202766987914, 4101.853236958118, 4783.963573018166, 3921.1102057839475, 4063.644210610431, 3757.6373055214485, 2792.27093376227, 12018.892271889263, 7016.6800724255945, 6366.266201445854, 5668.785099868198, 5266.062571071995, 5174.935523998805, 4805.334536505091, 4696.767027804693, 4539.80381400578, 4509.842574295015, 4104.310679451509, 3829.2948183701883, 3798.136587382236, 3627.85593418009, 3586.7094472310946, 3505.5687744270203, 3417.903334865397, 3393.377832709317, 3056.393622658623, 3023.96689610025, 2936.0017970992208, 2840.7364390551465, 2811.696522754234, 2765.777829866381, 2620.3312762963756, 2429.8899405747693, 2424.9462654590457, 2327.33984744605, 2230.4440033470614, 2161.0138050403957, 18474.37231014133, 7343.145624603268, 4705.689070077488, 5220.590074382378, 5199.428566969141, 4504.847152651293, 4636.957920321776, 2956.8118985450537, 9418.122625586791, 7242.783096019442, 6311.262643580938, 6151.434123736312, 5886.677951376673, 5821.43905378075, 5631.977922303395, 4758.924091008642, 4193.183445254713, 4110.13348388602, 3903.015511099306, 3660.2218289444186, 3580.236747830449, 3342.36467256681, 3249.481514886809, 3182.0233979760114, 3119.3093690484284, 3062.6738484521175, 3019.8715237090423, 2893.1835941286145, 2651.172206584198, 2676.3463446448022, 2586.0106531844267, 2573.4985987058135, 2428.0642531009667, 2400.166993628273, 2337.296412592817, 2299.8347977797744, 2217.7190238405014, 2197.2344600826914, 6288.862180217257, 6020.967976766778, 2939.4938975031596, 2799.979411441696, 5224.913554242993, 2609.56126201919, 3065.807919147373, 2921.1658856241856, 2815.615985073269], \"Total\": [42910.0, 32982.0, 21370.0, 39713.0, 20511.0, 21118.0, 17516.0, 41816.0, 17590.0, 14530.0, 15010.0, 21786.0, 13963.0, 12832.0, 12019.0, 13529.0, 11658.0, 11961.0, 11384.0, 11698.0, 18508.0, 10677.0, 11653.0, 10576.0, 10539.0, 10876.0, 10665.0, 10418.0, 9418.0, 10531.0, 13529.13979739102, 11653.187163738994, 10443.081557732869, 10143.302666944817, 10531.710633150262, 8407.320188454914, 8045.063652806685, 6869.4762422382, 6573.17186756905, 6566.095757532848, 6174.81797737812, 6122.255477225068, 5843.002145194177, 5449.640316078245, 5324.602607888288, 5103.2758200778835, 5075.68509394841, 4483.46664651896, 4223.067046827836, 4156.540168280883, 4116.310288761908, 3824.627566061679, 3592.9566677777834, 3413.4899365612964, 3331.798278516833, 3289.420938434053, 3130.9575627150325, 3103.4941238052556, 3076.817712118633, 3595.289690764229, 21786.425439130486, 7052.078937335376, 7767.781358381305, 7141.526920676673, 4902.478048894736, 5236.762680811952, 5884.199123840368, 8681.203410056925, 13963.502635139947, 10876.917632210427, 10418.34784949551, 8769.491936593422, 7610.824328934789, 7124.919444174944, 6812.685093768187, 6152.078306665662, 5529.4773389319125, 5469.888530964534, 5373.516852769251, 5126.833541261974, 5072.466525420761, 4986.529814544924, 4520.177312594843, 3961.1350418620195, 17590.031842629312, 3690.356045690224, 3922.529453040486, 3523.8339033284988, 3516.307263199949, 3354.2238666976427, 3285.9202204544304, 2949.8860866466057, 2889.807803669232, 2861.906563446984, 2809.206858175338, 2731.0366595718056, 2642.8807829236684, 2508.9123040103896, 5965.057962804205, 4028.815098960015, 3296.938705888126, 12260.252806773398, 9176.388004419585, 31624.42452903747, 4960.6364288197465, 21786.425439130486, 10792.184399409798, 8810.840084068719, 4473.573301340423, 21118.499410029453, 11961.774199033009, 11698.757090270234, 10665.370699377907, 8587.728035330783, 8193.838930701162, 7956.231784679409, 6448.040394833941, 15010.687224420966, 5939.4632371601665, 5904.735193474735, 5550.469619677149, 5426.680472417637, 4888.59206958528, 8357.965220225587, 4407.948168159879, 4006.3566434992317, 3968.2190887630986, 3777.9431659469624, 3757.3397305534454, 3620.151129175341, 3565.1717551366983, 3443.471361520087, 3144.2626795902684, 3130.79921630501, 3025.439963865631, 2959.9535078763674, 2897.531794663737, 2661.6481746456802, 2608.870010070096, 18508.750446556198, 4206.120267108725, 8973.43510679897, 32982.56500997309, 16963.449801839695, 9469.756546050132, 19049.022599554028, 4989.1394075152175, 21370.36291493879, 20511.430262094265, 17516.054933196174, 11658.592610261278, 11384.752066444376, 9187.047486399862, 5556.215451620607, 5506.818500146708, 5251.583956239518, 4455.332663610901, 4307.476277076656, 4161.713308128012, 4157.74389247981, 4148.52019959044, 4145.805737764322, 4113.1259797844805, 3886.1502086248424, 3869.7353903199787, 3618.9010291553896, 3388.5212266438757, 3340.934801260291, 3281.7503964609914, 3184.159740779347, 3123.5850460789366, 2973.41752236672, 2894.7559200400337, 2877.8131112018777, 2851.699460211128, 2768.5120789507537, 2766.8562036922276, 3726.6154370162035, 3763.4240111563395, 9244.823182163916, 12799.154956075334, 39713.70101191427, 41816.08131105197, 29264.600280282066, 19049.022599554028, 42910.35230616422, 12832.529372474748, 9254.183529391099, 5670.611678484549, 5652.614195732376, 4433.927411951525, 4368.643530881365, 4171.981622900605, 3877.6392211054185, 3732.5137837052444, 3528.585387231737, 3323.4121365297437, 3280.956998001122, 3154.8083950550194, 3148.782959760501, 3120.5904615132667, 3101.1607193783357, 2876.908247012733, 2669.6096754208215, 2473.714287401533, 2372.6278886463965, 2333.9548872162936, 2315.4637946542452, 2238.2627465709647, 2239.1666081809844, 2215.7840185584914, 2158.8758702186806, 2102.0652314444123, 2083.5671970684552, 2080.200155454745, 3524.4544958938404, 3222.4017795919654, 7116.33486614451, 12431.2413834213, 4717.916314520895, 9315.46633310153, 4804.581841943988, 5862.351955114021, 7635.533829636299, 41816.08131105197, 6670.86964796603, 29264.600280282066, 14734.407545041979, 9604.354298111428, 39713.70101191427, 10576.192292977104, 9156.022612649223, 7524.766055823591, 6141.034228319058, 5822.710902814613, 5202.866639197655, 4966.201106171681, 4899.537285233506, 4841.870111842457, 4386.056949015286, 4221.949053270809, 4112.361840973579, 4054.628016329101, 4020.736135894754, 3906.9462662546152, 3906.6767279833457, 3774.05917074626, 3731.502699838714, 3713.6430285690567, 3581.1538863981127, 3576.381676412663, 3534.3573492276814, 3464.8135107421567, 3291.751620165502, 3194.4021216124993, 3007.996573428545, 2915.989041660798, 2866.5231698291805, 2735.5161388649462, 2476.4944577999895, 6994.125412810436, 7078.160760333044, 14734.407545041979, 8838.868340393665, 5293.7719999180945, 31624.42452903747, 12799.154956075334, 29264.600280282066, 9127.024088686236, 7951.406728647168, 7797.980439107174, 6192.021178280817, 4865.129666960861, 4481.991303982205, 4460.475910518985, 4240.4156916517395, 3686.50836762059, 3627.6562111384173, 3564.303872646919, 3208.5726138442205, 3165.344037063212, 3092.4444615043553, 3031.252007860479, 2955.1846360383875, 2949.4029238476137, 2925.4762756016635, 2909.274215566883, 2813.798096596054, 2631.117068660659, 2613.8005013634456, 2358.6972407360336, 2295.1561544680103, 3562.2753018454086, 10539.157973752031, 2150.1542857083446, 2155.298555949573, 2025.9950597870038, 4652.831580510533, 2522.2297177169926, 3228.6322503791957, 8512.073698808961, 39713.70101191427, 41816.08131105197, 16340.473962454129, 11195.513758022933, 21711.17813678208, 29264.600280282066, 5734.827275762994, 14530.393046065807, 10677.700167115174, 9170.613411851295, 7561.159290564648, 7138.097127978625, 6236.689043815742, 6196.2673780135765, 6128.139881448232, 4907.428700685689, 4517.273814994578, 4327.421109962272, 4175.635352750842, 4084.2910349323433, 4027.266112733589, 3925.402676341071, 3857.209002790738, 3323.831172988315, 3236.757381353868, 3233.565237029211, 3212.64565854005, 3180.988198611417, 3080.349392904317, 3063.9984799171443, 2926.1995489510364, 2741.023496599602, 2585.0864464949973, 2558.508750698535, 2543.9136550275457, 2454.3187087156152, 2440.0296154879074, 4105.330797758911, 9111.687602469112, 6397.312061109097, 10693.440784640368, 12431.2413834213, 21711.17813678208, 12019.717817191833, 7017.505586907421, 6367.091716878265, 5669.610607370279, 5266.888078658127, 5175.761116262273, 4806.160131105966, 4697.592569943527, 4540.629389748004, 4510.668218075926, 4105.136214906485, 3830.1203283568047, 3798.9621241632826, 3628.681479173196, 3587.535015846712, 3506.39439258581, 3418.7294542873974, 3394.2033523063897, 3057.219159122107, 3024.7924413399273, 2936.8273571365025, 2841.5620543906452, 2812.5220499483257, 2766.6033875546805, 2621.1567695342515, 2430.715482206183, 2425.7717747252614, 2328.165401448503, 2231.2695465104057, 2161.83934055505, 32982.56500997309, 12206.179974864739, 7267.446464364003, 8939.819816172856, 9043.444099707265, 9093.12447893717, 11195.513758022933, 18508.750446556198, 9418.95089892349, 7243.61135394899, 6312.0908730909605, 6152.262351541268, 5887.5062834412, 5822.270142927744, 5632.806131590736, 4759.752339423272, 4194.011664045381, 4110.961706809226, 3903.8437388483185, 3661.0500592591434, 3581.064965235227, 3343.192900781356, 3250.309710764957, 3182.8516366875324, 3120.1376063868342, 3063.5020982351007, 3020.6997469087114, 2894.011943246953, 2652.000444702126, 2677.20093135397, 2586.8388661744743, 2574.3268455066623, 2428.892502820441, 2400.9953018193555, 2338.124642355055, 2300.663031618225, 2218.5473214481517, 2198.0626699723293, 8062.911655217256, 8331.879600043598, 4164.267193783793, 3774.0063503705364, 31624.42452903747, 3679.0353550289997, 11398.847842436044, 9839.629477616552, 16963.449801839695], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9099, -4.0592, -4.1689, -4.198, -4.1604, -4.3857, -4.4298, -4.5878, -4.6319, -4.6329, -4.6944, -4.7029, -4.7496, -4.8193, -4.8425, -4.885, -4.8904, -5.0145, -5.0744, -5.0902, -5.1, -5.1735, -5.236, -5.2872, -5.3115, -5.3243, -5.3737, -5.3825, -5.3911, -5.2354, -3.7869, -4.775, -4.7421, -4.8016, -5.1608, -5.1554, -5.1302, -5.0518, -3.7823, -4.0321, -4.0752, -4.2475, -4.3892, -4.4552, -4.5, -4.602, -4.7087, -4.7195, -4.7373, -4.7843, -4.795, -4.8121, -4.9103, -5.0423, -3.5515, -5.1131, -5.0521, -5.1593, -5.1615, -5.2087, -5.2292, -5.3372, -5.3577, -5.3674, -5.386, -5.4143, -5.4471, -5.4991, -4.6332, -5.0267, -5.2263, -4.1835, -4.5241, -4.003, -5.0555, -4.5491, -4.842, -4.9459, -5.1423, -3.3682, -3.9366, -3.9589, -4.0514, -4.268, -4.315, -4.3444, -4.5546, -3.7096, -4.6368, -4.6427, -4.7045, -4.7271, -4.8315, -4.2952, -4.9351, -5.0306, -5.0402, -5.0893, -5.0948, -5.132, -5.1473, -5.182, -5.273, -5.2773, -5.3115, -5.3334, -5.3547, -5.4396, -5.4597, -3.859, -5.0814, -4.5668, -3.7449, -4.2311, -4.7777, -4.4911, -5.1116, -3.2745, -3.3156, -3.4734, -3.8805, -3.9043, -4.1188, -4.6217, -4.6307, -4.6781, -4.8426, -4.8763, -4.9108, -4.9117, -4.914, -4.9146, -4.9225, -4.9793, -4.9835, -5.0506, -5.1164, -5.1305, -5.1484, -5.1786, -5.1978, -5.2471, -5.2739, -5.2798, -5.2889, -5.3185, -5.3191, -5.0217, -5.0131, -4.3977, -4.2358, -4.0534, -4.2476, -4.481, -5.0942, -2.5522, -3.7593, -4.0863, -4.5761, -4.5793, -4.8221, -4.837, -4.8831, -4.9562, -4.9944, -5.0506, -5.1105, -5.1234, -5.1626, -5.1645, -5.1735, -5.1797, -5.2548, -5.3296, -5.4059, -5.4476, -5.464, -5.472, -5.5059, -5.5055, -5.516, -5.542, -5.5687, -5.5776, -5.5792, -5.0536, -5.1524, -4.7507, -4.384, -5.0334, -4.6434, -5.074, -4.9743, -4.9129, -4.2032, -5.0006, -4.4992, -4.9433, -5.0565, -5.1208, -3.9461, -4.0903, -4.2865, -4.4897, -4.543, -4.6555, -4.7021, -4.7156, -4.7275, -4.8263, -4.8645, -4.8908, -4.9049, -4.9133, -4.942, -4.9421, -4.9767, -4.988, -4.9928, -5.0291, -5.0305, -5.0423, -5.0622, -5.1134, -5.1434, -5.2036, -5.2347, -5.2518, -5.2986, -5.3981, -4.3646, -4.6806, -4.2608, -4.8192, -5.0149, -4.4858, -4.7728, -4.9454, -4.0889, -4.2268, -4.2463, -4.4769, -4.7182, -4.8002, -4.805, -4.8556, -4.9956, -5.0117, -5.0293, -5.1345, -5.1481, -5.1714, -5.1914, -5.2168, -5.2188, -5.2269, -5.2325, -5.2658, -5.333, -5.3396, -5.4423, -5.4696, -5.03, -3.9454, -5.5349, -5.5325, -5.5944, -4.763, -5.3766, -5.1819, -4.3957, -3.1353, -3.258, -4.1223, -4.4194, -4.2799, -4.5061, -5.0873, -3.562, -3.8701, -4.0223, -4.2153, -4.2729, -4.4079, -4.4144, -4.4254, -4.6476, -4.7305, -4.7734, -4.8091, -4.8312, -4.8453, -4.8709, -4.8885, -5.0373, -5.0639, -5.0649, -5.0714, -5.0813, -5.1134, -5.1187, -5.1648, -5.2302, -5.2888, -5.2991, -5.3048, -5.3407, -5.3465, -4.8268, -4.6729, -4.8718, -4.8361, -4.9144, -5.2113, -3.7383, -4.2765, -4.3738, -4.4898, -4.5635, -4.581, -4.6551, -4.6779, -4.7119, -4.7185, -4.8127, -4.8821, -4.8903, -4.9361, -4.9475, -4.9704, -4.9958, -5.003, -5.1075, -5.1182, -5.1477, -5.1807, -5.191, -5.2075, -5.2615, -5.3369, -5.339, -5.3801, -5.4226, -5.4542, -3.3084, -4.231, -4.676, -4.5722, -4.5762, -4.7196, -4.6907, -5.1407, -3.9725, -4.2352, -4.3728, -4.3985, -4.4425, -4.4536, -4.4867, -4.6552, -4.7817, -4.8017, -4.8534, -4.9177, -4.9398, -5.0085, -5.0367, -5.0577, -5.0776, -5.0959, -5.11, -5.1528, -5.2402, -5.2307, -5.2651, -5.2699, -5.3281, -5.3396, -5.3662, -5.3823, -5.4187, -5.428, -4.3764, -4.4199, -5.1369, -5.1856, -4.5617, -5.256, -5.0949, -5.1432, -5.18], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1203, 2.1203, 2.1203, 2.1203, 2.1203, 2.1203, 2.1203, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1202, 2.1201, 2.1201, 2.1201, 2.1201, 2.1201, 2.1201, 2.1201, 2.1201, 1.767, 1.9068, 1.843, 1.8676, 1.8845, 1.824, 1.7326, 1.4222, 2.2164, 2.2164, 2.2164, 2.2164, 2.2164, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2163, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2162, 2.2161, 2.2161, 2.216, 2.2149, 2.2158, 1.9452, 1.8943, 1.1781, 1.9781, 1.0047, 1.4143, 1.5132, 1.9946, 2.2168, 2.2168, 2.2168, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2167, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2166, 2.2165, 2.2165, 2.2165, 2.2165, 2.2165, 1.8579, 2.1171, 1.8741, 1.3942, 1.5729, 1.6093, 1.197, 1.9163, 2.2986, 2.2986, 2.2986, 2.2985, 2.2985, 2.2985, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2984, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2983, 2.2979, 2.2967, 2.0133, 1.8499, 0.9, 0.6543, 0.7777, 0.5938, 2.3238, 2.3238, 2.3238, 2.3237, 2.3237, 2.3237, 2.3237, 2.3237, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3236, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3235, 2.3218, 2.3126, 1.922, 1.7309, 2.0503, 1.76, 1.9915, 1.8922, 1.6894, 0.6986, 1.7367, 0.7596, 1.0016, 1.3164, -0.1674, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 2.3304, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3303, 2.3302, 2.3302, 2.3302, 2.3302, 2.3302, 2.3254, 1.9974, 1.6841, 1.6367, 1.9536, 0.6954, 1.3129, 0.3133, 2.3349, 2.3349, 2.3349, 2.3349, 2.3349, 2.3348, 2.3348, 2.3348, 2.3348, 2.3348, 2.3348, 2.3348, 2.3348, 2.3348, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3347, 2.3346, 2.3346, 2.3346, 2.3346, 2.3346, 2.3333, 2.2812, 2.0979, 1.8181, 1.6438, 1.7192, 1.8002, 1.2774, 0.7526, 1.8012, 2.3969, 2.3968, 2.3968, 2.3968, 2.3968, 2.3968, 2.3968, 2.3968, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3967, 2.3966, 2.3966, 2.3966, 2.3966, 2.3966, 2.3966, 2.3966, 2.3966, 2.3966, 2.3961, 1.7526, 1.9074, 1.4294, 1.2005, 0.3459, 2.4102, 2.4102, 2.4102, 2.4102, 2.4102, 2.4102, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.4101, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.4099, 2.4099, 1.8307, 1.9021, 1.9757, 1.8724, 1.8568, 1.708, 1.5289, 0.5762, 2.4198, 2.4198, 2.4198, 2.4198, 2.4198, 2.4198, 2.4198, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4197, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4196, 2.4195, 2.4195, 2.1714, 2.0951, 2.0716, 2.1214, 0.6194, 2.0764, 1.1067, 1.2055, 0.624]}, \"token.table\": {\"Topic\": [2, 3, 3, 2, 6, 3, 4, 6, 7, 8, 9, 10, 1, 5, 4, 3, 3, 6, 2, 8, 9, 3, 8, 3, 5, 2, 3, 5, 9, 5, 5, 1, 2, 3, 4, 5, 6, 7, 9, 5, 3, 4, 1, 9, 7, 8, 10, 5, 6, 10, 9, 10, 6, 5, 5, 2, 4, 9, 2, 4, 8, 9, 8, 6, 9, 10, 9, 8, 10, 1, 2, 6, 9, 10, 1, 2, 4, 6, 9, 3, 4, 5, 6, 7, 9, 10, 9, 1, 3, 1, 5, 1, 2, 3, 3, 6, 3, 4, 5, 6, 5, 6, 4, 10, 5, 4, 1, 10, 10, 3, 1, 8, 1, 2, 6, 9, 4, 1, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 2, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 9, 5, 6, 7, 4, 9, 1, 6, 10, 5, 7, 9, 3, 5, 9, 10, 2, 2, 7, 5, 5, 9, 3, 9, 7, 5, 4, 10, 1, 2, 7, 9, 10, 1, 2, 3, 9, 4, 2, 3, 5, 6, 8, 9, 10, 1, 1, 9, 9, 1, 1, 10, 8, 8, 8, 7, 9, 10, 9, 5, 10, 9, 4, 7, 1, 2, 1, 2, 6, 8, 4, 7, 1, 8, 1, 2, 7, 9, 1, 9, 2, 3, 1, 8, 9, 2, 5, 8, 10, 5, 6, 8, 5, 6, 7, 10, 10, 2, 2, 3, 4, 9, 10, 1, 9, 10, 1, 2, 4, 1, 2, 7, 1, 7, 10, 6, 4, 3, 4, 5, 8, 6, 3, 8, 6, 5, 3, 5, 5, 7, 6, 7, 8, 10, 5, 6, 2, 1, 7, 10, 2, 7, 5, 2, 6, 3, 6, 10, 9, 1, 1, 7, 6, 10, 3, 10, 8, 3, 7, 4, 1, 7, 2, 6, 5, 7, 8, 9, 4, 4, 6, 1, 5, 8, 2, 9, 6, 9, 2, 2, 7, 3, 5, 1, 5, 1, 2, 8, 4, 6, 9, 8, 7, 5, 7, 2, 4, 7, 10, 2, 1, 2, 7, 10, 2, 3, 7, 8, 6, 1, 7, 10, 9, 7, 10, 3, 9, 10, 5, 1, 8, 10, 6, 4, 3, 1, 8, 6, 1, 6, 3, 2, 3, 4, 10, 7, 8, 3, 2, 4, 10, 2, 9, 1, 2, 8, 10, 2, 1, 2, 3, 4, 5, 6, 8, 9, 10, 9, 1, 8, 5, 5, 10, 8, 10, 6, 8, 8, 2, 1, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 3, 9, 5, 6, 6, 2, 2, 3, 4, 5, 7, 8, 3, 9, 3, 2, 7, 1, 4, 6, 9, 10, 2, 6, 4, 8, 1, 2, 4, 6, 9, 10, 8, 7, 8, 9, 6, 4, 6, 6, 9, 2, 7, 5, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 8, 7, 7, 10, 9, 1, 3, 8, 8, 6, 4, 7, 6, 10, 2, 1, 7, 8, 8, 1, 4, 4, 9, 1, 3, 7, 4, 4, 10, 9, 7, 3, 4, 10, 4, 5, 4, 4, 6, 1, 2, 5, 8, 10, 7, 6, 1, 4, 6, 5, 9, 7, 5, 3, 7, 9, 8, 2, 5, 6, 8, 4, 5, 8, 3, 4, 5, 6, 7, 3], \"Freq\": [0.9997395428290916, 0.9998788875044486, 0.9998754908644256, 0.9985566230226063, 0.0014892716227033651, 0.13971181307198352, 0.033852527665366824, 0.00018703053958766202, 0.16627014969343154, 0.38004605644212924, 0.1019316440752758, 0.17795955841766042, 0.999930672700304, 0.9996842975393198, 0.9998127004482651, 0.999816466323263, 0.9998746061388549, 0.9998315872733149, 0.9998709537445092, 0.9998011534264262, 0.9998529460218166, 0.9996713327667847, 0.9996865602071697, 0.999784895801015, 0.9995942933863113, 0.9998374159692791, 0.27642201774161407, 0.5690536373003092, 0.15447428486609036, 0.9994789989379432, 0.9999917897163438, 3.417097757777273e-05, 0.07521032164867777, 0.08488070830318746, 0.21852340160985662, 0.20922889570870243, 0.13302761571026925, 0.20547008817514742, 0.07360428570252246, 0.999852693204008, 0.0015942928519915715, 0.9980273253467237, 0.6785970216102982, 0.32136913795769445, 0.9996063514273319, 0.0002149228878579514, 0.9995854628209387, 0.9997112490293762, 0.9998334304417634, 0.9998419372753828, 0.999681843637022, 0.9997587836833994, 0.9998872663294996, 0.9997277759655396, 0.9994932452958749, 0.9997633533953711, 0.751772085096086, 0.24813887240437715, 0.9994873540503255, 0.00016764296444990364, 0.00016764296444990364, 0.00016764296444990364, 0.9996893422579033, 0.005520963120945638, 0.27184742323786676, 0.7226460641568193, 0.9998875218980946, 0.9999331111427615, 0.9997532973748812, 0.1886550418941456, 0.4483800332641309, 0.15835533722843556, 0.08348634221347014, 0.12110615901554435, 0.16608647046810965, 0.8009257384754197, 0.0046942340239977155, 0.022800565259417475, 0.005141303931045117, 0.0030194637869307337, 0.0932910190720668, 0.3651468793367615, 0.21177894284886595, 0.14993199493725023, 0.0035400609915739634, 0.17315063026433827, 0.9997866300047573, 0.999867788142818, 0.999976352011582, 0.23908859861041187, 0.7607171812169932, 0.2375154938396713, 0.7623823217443021, 0.9998386494546817, 0.9999152237555977, 0.9996777892169071, 0.9999352772406395, 0.20944174311497285, 0.26651902955686924, 0.5239436995617597, 0.7172320325395288, 0.2826468659862682, 0.9998056498988889, 0.9998271772202122, 0.9998921318335251, 0.9997510213326835, 0.9998564704831707, 0.9997026121431569, 0.9996757176546853, 0.9995984179062186, 0.9999157524123418, 0.9998895176894502, 0.30099286500446215, 0.4949584782369757, 0.09738004456026716, 0.10657326555022247, 0.9996357780784381, 0.8077050825174441, 0.013187600539698438, 0.17909612345848525, 0.9996012195859529, 0.014563775009664564, 0.005189391095397718, 0.03450825507216086, 0.19313144002964042, 0.19686206219960375, 0.035775710040161224, 0.5009555975409742, 0.004806763180529684, 0.0003826279148680345, 0.013822433424607747, 0.757745323720924, 0.24215408663252766, 0.9998994385093752, 6.661920170937242e-05, 0.9998875984559706, 0.003852574705996285, 0.0014352729296848905, 0.058493666941368434, 0.2469424845863109, 0.08281776606550184, 0.0006295056709144257, 0.5963684923974903, 0.0008561277124436189, 5.0360453673154056e-05, 0.008586457351272767, 0.5857703488864371, 0.41418376148008673, 0.9998351519909486, 0.9998169151444228, 0.999863387994785, 0.9998595816552572, 0.9998518582960173, 0.9998407846815416, 0.9998451112342313, 0.9994845854523181, 0.18782388101423123, 0.1645694957458026, 0.6475451897823972, 0.5252469340896512, 0.1526222572792488, 0.1561592736704249, 0.16600396929253172, 0.9997204645692332, 0.9996832309417216, 0.9999019691270934, 0.9996257145361469, 0.9999587476124634, 0.9997056495458145, 0.9999153910012435, 0.9998923017094887, 0.999948848215033, 0.999423057703559, 0.9998461787284149, 0.9998361031855046, 0.00011370076062926815, 0.9997707882131548, 5.6850380314634074e-05, 0.9998738566755834, 0.9996431851775358, 0.9998359144646534, 0.00011964634616809392, 0.9997648685805928, 0.9998508681185413, 0.9997262471925211, 0.008766051313378714, 0.0001638514264182937, 0.16737423208628702, 0.1655718663956858, 8.192571320914685e-05, 0.6015805120947654, 0.05652874211431133, 0.9998825030568796, 0.41600391019873, 0.584016244998002, 0.999707495258436, 0.9997949322386597, 0.9998715736888082, 0.9997118084616856, 0.9997660061399007, 0.999813992260248, 0.9995797252751565, 0.9998742701248317, 0.9998613871131116, 0.9997838697179597, 0.9994994335678308, 0.9997437577964207, 0.9995189981172593, 0.9998022023169345, 0.9997713426158794, 0.9998621005108641, 0.7435891670760687, 0.2562651931731084, 0.7898046582529712, 0.2098938515863397, 0.6860892384591166, 0.3137649298129385, 0.9997547216244603, 0.9996937404507238, 0.9999619155155582, 0.9996408466829289, 0.7022721576215871, 0.2976624145213067, 0.9998913113206073, 0.9996454684114398, 0.9998650243394281, 0.9998285375919164, 0.9999640036491502, 0.9997564762120499, 0.24791439801928705, 0.17703432258201543, 0.574891594693253, 0.33078825607251827, 0.6691646879427918, 0.99989741782582, 0.9997131808519013, 0.9998623491472457, 0.9999120113969607, 0.9999729500733696, 0.9998759899426214, 0.20958465153439912, 0.7888794478999385, 0.0014097622300520121, 0.9999140071505955, 0.9996351267099988, 0.07390199062561885, 0.1483538472529164, 0.1569317568791043, 0.4954292675125192, 0.12536944838274625, 0.9996816836754301, 0.9998143836958238, 0.999516542459482, 0.9996941629850128, 0.9995703918450057, 0.999700883477953, 0.2752717080820268, 0.7245770336648439, 0.9998371972435273, 0.9998331188619064, 0.9997163632326642, 0.9996325474184613, 0.9997577990097308, 0.9998888037886505, 0.9997503493553149, 0.2358708690425364, 0.530152847242747, 0.23390636985561913, 0.9997193550237713, 0.999909582157109, 0.9997990259092739, 0.9998202942618537, 0.9997513452751406, 0.9997447245096883, 0.9997083174202817, 0.649398062270718, 0.350371321225126, 0.9996608212010856, 0.9994631614503122, 0.9996266005742485, 0.9996503320418859, 0.9998107853239478, 0.9998268469629122, 0.9998916899275082, 0.9998700437722206, 0.9996419979542996, 0.0002807194602511372, 0.9998650225455732, 0.9998191087853356, 0.9997716237596699, 0.999620415358332, 0.9997581438717437, 0.5446813732662874, 0.18501003605322516, 0.2702286999202073, 0.9997182819975808, 0.9998964330856855, 0.9998675301229741, 0.99988779599174, 0.25781620635176455, 0.7419171405806174, 0.9996927869314094, 0.9997683494000265, 0.999578031561022, 0.9996665184287687, 0.9998933049906484, 0.9998859822591085, 0.9997342344606857, 0.9995088537939928, 0.9998937508518692, 0.9998932786130796, 0.18310362397533786, 0.5401924093684183, 0.14412066659823553, 0.13255429462920515, 0.9998099636678471, 0.9997040236318478, 0.9998003396299022, 0.2738773348025258, 0.5559994716927029, 0.1701427339906222, 0.9999666118370651, 0.9999279534727604, 0.9998988927286145, 0.999738017944935, 0.9996667337666688, 0.9999439036380923, 0.9995754393926579, 0.9999652427104171, 0.9996461665252909, 0.9998981254036073, 0.9997647106364955, 0.21126321491965178, 0.7880037281688157, 0.0006047611114112169, 0.9999339409027103, 0.999888312568406, 0.9997586158025703, 0.9998478428557169, 0.9995620159969573, 0.0002846527215429881, 0.99960547381846, 0.9996363746915621, 0.999690549985545, 0.9996341858905675, 0.9997818474758876, 0.9997199504574998, 0.9998284879640168, 0.9999080278956158, 0.9998562750245354, 0.9996227584712044, 0.9999156349030621, 0.20248718793871254, 0.2723973986254116, 0.5250399496470465, 0.9998267765596016, 0.9999325244326382, 0.29392926607282194, 0.7057664321797579, 0.9995586797601362, 0.9983230243909658, 0.0015858983707561015, 0.4392926989037661, 0.5601141086029522, 0.0005760619283022676, 0.9997996968662105, 0.9997499997799719, 0.9997954610515883, 0.999915600945562, 0.999877908619116, 0.9997812446923287, 0.9998545785502652, 0.9997337380140532, 0.9996856148319611, 0.9998903395969401, 0.9996412832135497, 0.9998981953966531, 0.9996820217901778, 0.9997134553985098, 0.9999220068983223, 0.9999790233012146, 0.9997660628150263, 0.9998215362676381, 0.9997180124458362, 0.9996778639009599, 0.9998375595847148, 0.999949169657, 0.9995514227789534, 0.9994119678704783, 0.00030331167461926503, 0.7765846242128995, 0.22334159315174446, 0.9997499352569199, 0.9996353986489231, 0.9996996200461378, 0.15884744476969925, 0.17907178354715936, 0.026525389049834616, 0.1196183253320128, 0.013618398975777159, 0.09431249439941197, 0.003455414665495697, 0.10752437400277787, 0.2968607717033215, 0.9998121964749159, 0.38688123642524186, 0.6129136678882317, 0.9994358363097008, 0.9998721087184688, 0.9997324296622199, 0.9998462996567635, 0.9998568863241688, 0.9996686919668232, 0.9998466781983956, 0.9998251969613174, 0.9999038148044543, 0.9998217196214156, 0.9997388657071912, 0.9998865736123564, 0.1064683405356018, 0.35406177872798733, 0.0013597085366887072, 0.09410447919036262, 0.06359008993676722, 0.19491263767788816, 3.162112876020249e-05, 0.012332240216478973, 0.007936903318810825, 0.16522039777205802, 0.9999402800296354, 0.9998451798900855, 0.9998313845586115, 0.9887035254813648, 0.010861463713699865, 0.9998652821988483, 0.9998247248146218, 0.09462401803208163, 0.9051096398194342, 0.9997201976943884, 0.9978849220772958, 0.001986122961200191, 0.9995900659093921, 0.7404082544648223, 0.2593633679689984, 0.9998631144358119, 0.9999136737701135, 0.9995991329868392, 0.9998959183694781, 0.638479651824281, 0.3614301112749785, 0.9996117470251815, 0.9997948150665338, 0.9999035199623516, 0.9998174897608758, 0.0007307571905381393, 0.9991886651958158, 0.11974894470635256, 0.19914293368748742, 0.15141881213418645, 0.1603670849254304, 0.10027329216070402, 0.26897455272503806, 0.9999026880094238, 0.5864169639795416, 0.22145392335831632, 0.19198485796654036, 0.9997590206813154, 0.9998513660570643, 0.9998113193859056, 0.7167116107943985, 0.28312439740429224, 0.05203441797382429, 0.947460027273384, 0.9997353615164851, 0.14273753273433912, 0.0003224145624847931, 0.1440271909842783, 0.12514290946731182, 0.34728654301933426, 0.12859735120822033, 0.06816765035392769, 0.04366414360508341, 0.9998341014408053, 0.9997752096818712, 0.9999344271608852, 0.9998350815910645, 0.2905652968348747, 0.7094250933012376, 0.9997467402590926, 0.999872032664128, 0.7097616380124432, 0.29007843362323593, 0.9996839023171216, 0.999771665589561, 0.9998150345975924, 0.9993975053033891, 0.21989574930450187, 0.7799911829531936, 0.9996282283935678, 0.9997473289398431, 0.9997043958317363, 0.9999126425034705, 0.9994626986662603, 0.0005366800073155238, 0.9992981736215053, 0.9998286022906435, 0.9994310205540199, 0.9997604061080227, 0.9998976144505333, 0.999586966752605, 0.9999830178392275, 0.9997174551750033, 0.999597050471646, 0.9997819031244612, 0.9997678033190909, 0.9999352845550692, 0.9999397733564894, 0.9998990440725625, 0.999821082659479, 0.9997908373625998, 0.9998746059883012, 0.9998894301335587, 0.9997652079283245, 0.4975116692919051, 0.0981430753037053, 0.0943417590067308, 0.18925947502815468, 0.12072059027967505, 0.9997788250991643, 0.9998741167839269, 0.9998868257534571, 0.0050041996581722745, 0.9948348920446481, 0.9995908716053066, 0.9997232211437078, 0.9994962632648068, 0.9998913430651538, 0.6984264030857492, 0.14182480916686716, 0.15976227074530522, 0.9996741251917425, 0.28397300461296493, 0.00011313665522428883, 0.49972460612568376, 0.21620414813361594, 0.1449573654328042, 0.5527203428905648, 0.30230287419338414, 0.3606484250882688, 0.18179410423299489, 0.154863588647801, 0.15376116988115565, 0.14887902962886904, 0.9999109805913534], \"Term\": [\"aboriginal\", \"abuse\", \"accused\", \"action\", \"action\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"adelaide\", \"aged\", \"airport\", \"alan\", \"allegation\", \"alleged\", \"amid\", \"andrew\", \"animal\", \"announces\", \"appeal\", \"arrest\", \"arrested\", \"artist\", \"assault\", \"attack\", \"attack\", \"attack\", \"aussie\", \"australia\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"baby\", \"bank\", \"bank\", \"beach\", \"beach\", \"beat\", \"beat\", \"berejiklian\", \"best\", \"biden\", \"black\", \"boat\", \"body\", \"border\", \"boris\", \"breach\", \"briefing\", \"brisbane\", \"brisbane\", \"budget\", \"budget\", \"budget\", \"budget\", \"building\", \"bushfire\", \"bushfire\", \"bushfire\", \"bushfires\", \"business\", \"cabinet\", \"call\", \"call\", \"call\", \"call\", \"call\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"campaign\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"cancer\", \"care\", \"case\", \"centre\", \"centre\", \"change\", \"change\", \"charge\", \"charged\", \"chief\", \"child\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"christmas\", \"claim\", \"climate\", \"close\", \"closure\", \"club\", \"coach\", \"coal\", \"coast\", \"commission\", \"community\", \"community\", \"community\", \"community\", \"company\", \"concern\", \"concern\", \"concern\", \"continues\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"council\", \"council\", \"country\", \"court\", \"court\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crash\", \"crash\", \"cricket\", \"crisis\", \"cut\", \"cyclone\", \"daniel\", \"data\", \"david\", \"day\", \"dead\", \"dead\", \"dead\", \"death\", \"death\", \"death\", \"death\", \"decision\", \"defends\", \"doctor\", \"domestic\", \"donald\", \"drone\", \"drug\", \"drum\", \"dy\", \"early\", \"east\", \"economy\", \"election\", \"election\", \"election\", \"emergency\", \"expert\", \"extended\", \"face\", \"face\", \"facebook\", \"fall\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"farm\", \"farmer\", \"farmer\", \"fatal\", \"fear\", \"federal\", \"female\", \"festival\", \"fight\", \"film\", \"final\", \"finance\", \"find\", \"flooding\", \"footage\", \"football\", \"france\", \"free\", \"friday\", \"funding\", \"funding\", \"future\", \"future\", \"game\", \"game\", \"george\", \"global\", \"gold\", \"good\", \"government\", \"government\", \"grand\", \"great\", \"green\", \"guilty\", \"health\", \"hears\", \"help\", \"help\", \"help\", \"high\", \"high\", \"hill\", \"history\", \"hit\", \"hobart\", \"home\", \"hong\", \"hospital\", \"hospital\", \"hospital\", \"hotel\", \"hour\", \"house\", \"house\", \"house\", \"house\", \"house\", \"housing\", \"human\", \"hunt\", \"impact\", \"increase\", \"india\", \"indigenous\", \"indigenous\", \"indonesia\", \"industry\", \"injured\", \"inside\", \"international\", \"interview\", \"investigation\", \"island\", \"island\", \"island\", \"jail\", \"jailed\", \"james\", \"john\", \"johnson\", \"kid\", \"kill\", \"killed\", \"killed\", \"killing\", \"king\", \"know\", \"kohler\", \"kong\", \"korea\", \"labor\", \"land\", \"latest\", \"latest\", \"law\", \"lead\", \"leaf\", \"legal\", \"liberal\", \"life\", \"life\", \"life\", \"like\", \"live\", \"local\", \"lockdown\", \"long\", \"long\", \"look\", \"loss\", \"making\", \"march\", \"mark\", \"market\", \"mask\", \"medical\", \"medium\", \"meet\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"mental\", \"michael\", \"military\", \"million\", \"million\", \"million\", \"minister\", \"missing\", \"monday\", \"money\", \"morning\", \"morrison\", \"mount\", \"murder\", \"music\", \"national\", \"near\", \"need\", \"need\", \"need\", \"news\", \"north\", \"northern\", \"number\", \"online\", \"open\", \"open\", \"opposition\", \"outback\", \"outbreak\", \"pandemic\", \"parent\", \"park\", \"parliament\", \"patient\", \"paul\", \"people\", \"perth\", \"perth\", \"perth\", \"peter\", \"plan\", \"player\", \"player\", \"pleads\", \"point\", \"point\", \"police\", \"police\", \"police\", \"politics\", \"port\", \"power\", \"premier\", \"president\", \"price\", \"prime\", \"prince\", \"prison\", \"program\", \"project\", \"protest\", \"protester\", \"push\", \"quarantine\", \"queensland\", \"question\", \"race\", \"rain\", \"rape\", \"rate\", \"record\", \"recovery\", \"refugee\", \"refugee\", \"regional\", \"regional\", \"release\", \"released\", \"remote\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"rescue\", \"resident\", \"resident\", \"response\", \"restriction\", \"result\", \"return\", \"road\", \"rollout\", \"royal\", \"rugby\", \"rule\", \"rural\", \"sale\", \"save\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"scott\", \"search\", \"security\", \"security\", \"sentenced\", \"service\", \"sexual\", \"sexual\", \"share\", \"shark\", \"shark\", \"ship\", \"shooting\", \"shooting\", \"shot\", \"show\", \"smith\", \"social\", \"south\", \"south\", \"southern\", \"speaks\", \"sport\", \"staff\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"storm\", \"storm\", \"storm\", \"story\", \"street\", \"strike\", \"student\", \"student\", \"super\", \"super\", \"survivor\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"take\", \"talk\", \"tasmania\", \"tasmanian\", \"team\", \"team\", \"teen\", \"territory\", \"test\", \"test\", \"testing\", \"thousand\", \"thursday\", \"tiger\", \"time\", \"time\", \"told\", \"tourism\", \"tourist\", \"town\", \"track\", \"trade\", \"trade\", \"travel\", \"treatment\", \"tree\", \"trial\", \"truck\", \"trump\", \"tuesday\", \"turnbull\", \"united\", \"update\", \"vaccine\", \"victoria\", \"victorian\", \"video\", \"violence\", \"wall\", \"warning\", \"warns\", \"water\", \"water\", \"water\", \"water\", \"water\", \"weather\", \"wednesday\", \"week\", \"west\", \"west\", \"whale\", \"white\", \"wild\", \"win\", \"woman\", \"woman\", \"woman\", \"womens\", \"worker\", \"worker\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\", \"year\", \"zealand\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 6, 1, 7, 9, 10, 5, 8, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el93943136815929128609631440\", ldavis_el93943136815929128609631440_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el93943136815929128609631440\", ldavis_el93943136815929128609631440_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el93943136815929128609631440\", ldavis_el93943136815929128609631440_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "vis = pyLDAvis.gensim_models.prepare(topic_model=lda_model, corpus=bow_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 : police : 0.036574744\n",
      "1116 : school : 0.02379447\n",
      "805 : family : 0.014537634\n",
      "313 : missing : 0.013891312\n",
      "829 : guilty : 0.012603652\n",
      "3276 : drum : 0.01122281\n",
      "541 : search : 0.010425517\n",
      "455 : farmer : 0.010335493\n",
      "111 : help : 0.010293598\n",
      "1023 : announces : 0.010245108\n",
      "361 : northern : 0.009513388\n",
      "649 : dead : 0.009316115\n",
      "746 : emergency : 0.009298451\n",
      "195 : crash : 0.009180044\n",
      "545 : finance : 0.008987702\n",
      "9637 : daniel : 0.0089283865\n",
      "284 : house : 0.008918497\n",
      "286 : white : 0.008125532\n",
      "1072 : fatal : 0.007581068\n",
      "593 : teen : 0.0075193825\n"
     ]
    }
   ],
   "source": [
    "#get the top 20 words and their weights for a specific topic\n",
    "topic_id=1\n",
    "top_terms=20\n",
    "for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "    print(wordid, \":\", dictionary[wordid], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility function to get the id for a word\n",
    "\n",
    "def get_id_for_word(dictionary, word):\n",
    "    for k, v in dictionary.iteritems():\n",
    "        if (v==word):\n",
    "            return k\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 6\n",
      "8173 : trump : 0.03783449\n",
      "2232 : queensland : 0.03631376\n",
      "1619 : victoria : 0.031010482\n",
      "26 : record : 0.020639911\n",
      "1363 : news : 0.02015508\n",
      "18896 : covid : 0.017362405\n",
      "1188 : market : 0.016264068\n",
      "144 : south : 0.014468464\n",
      "18895 : coronavirus : 0.014299195\n",
      "679 : brisbane : 0.012305363\n",
      "16 : australian : 0.011321955\n",
      "852 : price : 0.009835721\n",
      "3206 : street : 0.009748264\n",
      "1422 : interview : 0.009296374\n",
      "856 : india : 0.00788662\n",
      "1416 : warning : 0.007624842\n",
      "1415 : travel : 0.0073667704\n",
      "3056 : video : 0.0073597427\n",
      "2264 : wall : 0.0073434124\n",
      "730 : christmas : 0.0073386063\n"
     ]
    }
   ],
   "source": [
    "top_terms=20\n",
    "index=get_id_for_word(dictionary,'market')\n",
    "for topic_id, score in lda_model.get_term_topics(index):\n",
    "    print(\"Topic:\", topic_id)\n",
    "    for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "        print(wordid, \":\", dictionary[wordid], \":\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading your model for re-use\n",
    "\n",
    "Building a model takes time.Once you have a stable model, you can save it to disk and reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LdaModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m lda_model.save(temp_file)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load a potentially pretrained model from disk.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m loaded_lda = \u001b[43mLdaModel\u001b[49m.load(temp_file)\n",
      "\u001b[31mNameError\u001b[39m: name 'LdaModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model to disk.\n",
    "temp_file = \"./model\"\n",
    "lda_model.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "loaded_lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare any new text against the topic model, we first need to process it in the same way as we processed the input texts for the model.\n",
    "We apply the same preprocessing function and next apply the *doc2bow* function to represent it using the same vector representation as we used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(888, 1), (1088, 1), (1922, 1), (5668, 1), (12411, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "print(bow_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this representation of the unseen document into the model to compare it against all the topics.\n",
    "The next function returns in index to the topics and a similarity score for the new document. We print the scores and the topics with the top 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.34985023736953735\t Topic_id 8\t Topic: 0.078*\"australia\" + 0.023*\"donald\" + 0.017*\"restriction\" + 0.015*\"coronavirus\" + 0.012*\"world\"\n",
      "Score: 0.3137676417827606\t Topic_id 6\t Topic: 0.038*\"trump\" + 0.036*\"queensland\" + 0.031*\"victoria\" + 0.021*\"record\" + 0.020*\"news\"\n",
      "Score: 0.21967032551765442\t Topic_id 9\t Topic: 0.019*\"border\" + 0.017*\"north\" + 0.014*\"china\" + 0.014*\"protest\" + 0.013*\"west\"\n",
      "Score: 0.016674285754561424\t Topic_id 5\t Topic: 0.029*\"election\" + 0.023*\"health\" + 0.018*\"say\" + 0.018*\"people\" + 0.017*\"minister\"\n",
      "Score: 0.01667400449514389\t Topic_id 3\t Topic: 0.023*\"government\" + 0.020*\"coast\" + 0.017*\"national\" + 0.016*\"plan\" + 0.015*\"live\"\n",
      "Score: 0.016673361882567406\t Topic_id 0\t Topic: 0.034*\"case\" + 0.024*\"court\" + 0.024*\"police\" + 0.021*\"woman\" + 0.020*\"child\"\n",
      "Score: 0.01667252741754055\t Topic_id 1\t Topic: 0.037*\"police\" + 0.024*\"school\" + 0.015*\"family\" + 0.014*\"missing\" + 0.013*\"guilty\"\n",
      "Score: 0.01667252741754055\t Topic_id 2\t Topic: 0.019*\"victorian\" + 0.014*\"premier\" + 0.013*\"claim\" + 0.013*\"time\" + 0.012*\"speaks\"\n",
      "Score: 0.01667252741754055\t Topic_id 4\t Topic: 0.043*\"covid\" + 0.038*\"coronavirus\" + 0.019*\"open\" + 0.017*\"lockdown\" + 0.016*\"melbourne\"\n",
      "Score: 0.01667252741754055\t Topic_id 7\t Topic: 0.028*\"home\" + 0.021*\"tasmania\" + 0.018*\"business\" + 0.015*\"royal\" + 0.014*\"return\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic_id {}\\t Topic: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text matches best with topic 5 although the score is not very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the model with a new document\n",
    "\n",
    "We can also use the unseen documents to extend our model and update the topics. This is useful when processing texts in a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timofeypolivanov/.pyenv/versions/3.12.6/envs/env12/lib/python3.12/site-packages/gensim/models/ldamodel.py:850: RuntimeWarning: overflow encountered in exp2\n",
      "  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words\n"
     ]
    }
   ],
   "source": [
    "# Update the model by incrementally training on the new corpus.\n",
    "\n",
    "other_texts = [['computer', 'time', 'graph'],['survey', 'response', 'eps'],['human', 'system', 'computer']]\n",
    "other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "# Update the model by incrementally training on the new corpus.\n",
    "lda_model.update(other_corpus)  # update the LDA model with additional documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
